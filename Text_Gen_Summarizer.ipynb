{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b10f84d-ad1a-47d0-9c22-635fcc624089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Parsing Tools for Summarizers\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "\n",
    "# Extractive Text Summarizer Libraries\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.kl import KLSummarizer\n",
    "\n",
    "# Abstractive Text Summarizers\n",
    "## T5 Models\n",
    "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
    "## BART Model\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig\n",
    "## GPT-2 Model\n",
    "from transformers import GPT2Tokenizer,GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1dec6dd-8aa9-4a48-b52a-353ba631d52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>car, call, company, tell, work, would, say, da...</td>\n",
       "      <td>Giving this location a low rating only because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>order, wait, ask, say, minute, table, take, te...</td>\n",
       "      <td>I'll start off by saying that this was my favo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>order, wait, ask, say, minute, table, take, te...</td>\n",
       "      <td>The mille crepe cake my sister gifted me for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>pizza, restaurant, love, service, bar, order, ...</td>\n",
       "      <td>Go someplace else there are better hotels in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>car, call, company, tell, work, would, say, da...</td>\n",
       "      <td>Used them a number of years ago and they were ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  \\\n",
       "0            0             9.0   \n",
       "1            1             3.0   \n",
       "2            2             3.0   \n",
       "3            3             7.0   \n",
       "4            4             9.0   \n",
       "\n",
       "                                      Topic_Keywords  \\\n",
       "0  car, call, company, tell, work, would, say, da...   \n",
       "1  order, wait, ask, say, minute, table, take, te...   \n",
       "2  order, wait, ask, say, minute, table, take, te...   \n",
       "3  pizza, restaurant, love, service, bar, order, ...   \n",
       "4  car, call, company, tell, work, would, say, da...   \n",
       "\n",
       "                                                Text  \n",
       "0  Giving this location a low rating only because...  \n",
       "1  I'll start off by saying that this was my favo...  \n",
       "2  The mille crepe cake my sister gifted me for m...  \n",
       "3  Go someplace else there are better hotels in t...  \n",
       "4  Used them a number of years ago and they were ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['Document_No', 'Dominant_Topic', 'Topic_Keywords', 'Text']\n",
    "data = pd.read_csv('data/top_dominant_results.csv',usecols=col_names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f598ae90-4a1f-4539-b4ca-b084ed14d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in Dataframe: 335433\n",
      "\n",
      "Document_No         0\n",
      "Dominant_Topic    143\n",
      "Topic_Keywords    143\n",
      "Text                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Rows in Dataframe: {len(data)}\\n')\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8114f809-6622-49f1-8673-63bb1a8b7e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in Dataframe: 335290\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>car, call, company, tell, work, would, say, da...</td>\n",
       "      <td>Giving this location a low rating only because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>order, wait, ask, say, minute, table, take, te...</td>\n",
       "      <td>I'll start off by saying that this was my favo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>order, wait, ask, say, minute, table, take, te...</td>\n",
       "      <td>The mille crepe cake my sister gifted me for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>pizza, restaurant, love, service, bar, order, ...</td>\n",
       "      <td>Go someplace else there are better hotels in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>car, call, company, tell, work, would, say, da...</td>\n",
       "      <td>Used them a number of years ago and they were ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  \\\n",
       "0            0               9   \n",
       "1            1               3   \n",
       "2            2               3   \n",
       "3            3               7   \n",
       "4            4               9   \n",
       "\n",
       "                                      Topic_Keywords  \\\n",
       "0  car, call, company, tell, work, would, say, da...   \n",
       "1  order, wait, ask, say, minute, table, take, te...   \n",
       "2  order, wait, ask, say, minute, table, take, te...   \n",
       "3  pizza, restaurant, love, service, bar, order, ...   \n",
       "4  car, call, company, tell, work, would, say, da...   \n",
       "\n",
       "                                                Text  \n",
       "0  Giving this location a low rating only because...  \n",
       "1  I'll start off by saying that this was my favo...  \n",
       "2  The mille crepe cake my sister gifted me for m...  \n",
       "3  Go someplace else there are better hotels in t...  \n",
       "4  Used them a number of years ago and they were ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(subset=['Dominant_Topic','Topic_Keywords'], inplace=True)\n",
    "print(f'Number of Rows in Dataframe: {len(data)}\\n')\n",
    "data['Dominant_Topic'] = data['Dominant_Topic'].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2553f1-11bd-4357-9622-8a8349b02280",
   "metadata": {},
   "source": [
    "Data currently stored in Dataframe format, however Summari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e605497d-ca6f-440b-9933-4d8002f7b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group text by topic number\n",
    "grouped_text = data.groupby(['Dominant_Topic'], as_index = False).agg({'Text': '.'.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016191c8-13d8-4a24-84e3-0606894c0bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to remove linebreaks from compiled text data\n",
    "def remove_linebreaks(text):\n",
    "    cleaned_string = '.'.join(text.splitlines())\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c860394-2fbd-4cff-8e6d-d451c3606f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat new dataframe with grouped, cleaned text data through lambda application\n",
    "grouped_text['Text'] = grouped_text.apply(lambda row : remove_linebreaks(row['Text']),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f300d0-c12d-489f-bfef-548f21ac4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Save formatted data to Text format\n",
    "def store_as_txt(groupby_column, target_column, file_location):\n",
    "    ## Loop through dataframe by Topic Number\n",
    "    for i in groupby_column:\n",
    "        ## Store text data as local variable\n",
    "        item = target_column.loc[groupby_column == i].item()\n",
    "        ## Create unique text_doc for each topic\n",
    "        with open(f\"{file_location}{i}.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "            text_file.write(item)\n",
    "        print(f\"Text Document {i} Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a74b39a-fed6-46eb-a6ff-e027fbdb2e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Document 0 Complete\n",
      "Text Document 1 Complete\n",
      "Text Document 2 Complete\n",
      "Text Document 3 Complete\n",
      "Text Document 4 Complete\n",
      "Text Document 5 Complete\n",
      "Text Document 6 Complete\n",
      "Text Document 7 Complete\n",
      "Text Document 8 Complete\n",
      "Text Document 9 Complete\n",
      "Text Document 10 Complete\n",
      "Text Document 11 Complete\n",
      "Text Document 12 Complete\n",
      "Text Document 13 Complete\n",
      "Text Document 14 Complete\n",
      "Text Document 18 Complete\n"
     ]
    }
   ],
   "source": [
    "# Designate Textfile-Save Directory Location\n",
    "file_loc = \"data/Text_Gen_Files/Clean_Text_Topic_\"\n",
    "# Execute Save Function\n",
    "store_as_txt(grouped_text['Dominant_Topic'], grouped_text['Text'],file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65474e3-364f-4333-b7b8-57e0c9ad4b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load txt file as compiled string variable\n",
    "def load_txt_file(file_loc,filename):\n",
    "    with open(f\"{file_loc}{filename}.txt\",\"r\",encoding=\"utf-8\") as text_file:\n",
    "        contents = text_file.read()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c18d311-19ff-45c5-be71-41bcc8cdd59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_dir = \"data/Text_Gen_Files/\"\n",
    "filename = \"Clean_Text_Topic_0\"\n",
    "topic_1_txt = load_txt_file(file_dir,filename)\n",
    "# topic_1_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e8250-39bf-4f5b-8f9a-9fc62b38d9ab",
   "metadata": {},
   "source": [
    "## Extractive Summarizers to be evaluated:\n",
    "1) LexRank\n",
    "2) LSA\n",
    "3) Luhn \n",
    "4) KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39bfab-8c89-4a4f-b319-2f1263254ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Text Parser and Tokenizer for string variable as input\n",
    "text_parser = PlaintextParser.from_string(topic_1_txt, Tokenizer('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed9b92-336f-4ef7-ac8b-e8f554f33390",
   "metadata": {},
   "source": [
    "### 1. LexRank Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e19844-7ccc-467c-a873-59c6ce3e178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LexRank Summarizer model\n",
    "lex_rank_summarizer = LexRankSummarizer()\n",
    "lexrank_summary = lex_rank_summarizer(text_parser.document, sentences_count=10)\n",
    "\n",
    "# Print Summarized Text\n",
    "for sentence in lexrank_summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c9b2e8-82cd-4afd-8163-09b66be1af8a",
   "metadata": {},
   "source": [
    "### 2. LSA Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b0b87-0a5b-4d66-81b7-90b63bdddde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_summarizer = LsaSummarizer()\n",
    "lsa_summary = lsa_summarizer(text_parser.document,sentences_count=10)\n",
    "\n",
    "# Printing the summary\n",
    "for sentence in lsa_summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48031044-bb57-4625-909f-9b18a7f17e79",
   "metadata": {},
   "source": [
    "### 3. Luhn Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30ad06-b8f9-4a2a-9f37-2c6c46552885",
   "metadata": {},
   "outputs": [],
   "source": [
    "luhn_summarizer = LuhnSummarizer()\n",
    "luhn_summary = luhn_summarizer(text_parser.document,sentences_count=10)\n",
    "\n",
    "# Printing the summary\n",
    "for sentence in luhn_summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fceb4-945c-4920-a621-740ebea3a698",
   "metadata": {},
   "source": [
    "### 4. KL Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b18f6b-0a25-467a-8c4d-def7601958bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_summarizer = KLSummarizer()\n",
    "kl_summary = kl_summarizer(text_parser.document,sentences_count=10)\n",
    "\n",
    "# Printing the summary\n",
    "for sentence in kl_summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a86f56-a9e2-4989-9262-0be4899dd96b",
   "metadata": {},
   "source": [
    "## Abstractive Sumamrizer to be evaluated:\n",
    "\n",
    "1) T5 Transformer\n",
    "2) BART Model\n",
    "3) GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8008ed29-c47d-4d2c-a360-d4b3fc29c3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
