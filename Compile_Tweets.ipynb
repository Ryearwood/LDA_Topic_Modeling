{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550941b5-c047-4a3d-8665-91b7f6de38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS Navigation libraries\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Computing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849fbaab-9f4c-48d2-8f7d-b12c3a01171a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current files in Path Folder: ['#angry.csv', '#fear.csv', '#happy.csv', '#joy.csv', '#love.csv', '#rage.csv', '#sad.csv', '#surprise.csv', 'DNN_Train_Data.csv']\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\russe\\Desktop\\LDA_Topic_Modeling\\data\\Datasets\\Emotion_Data\"\n",
    "extension = 'csv'\n",
    "os.chdir(path)\n",
    "result = glob.glob(f'*.{extension}')\n",
    "print(f\"Current files in Path Folder: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4163ad3-e426-4de3-b5f0-71cded9ec86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load All Dataframes and store into variables in a dictionary\n",
    "dfs = {os.path.splitext(os.path.basename(f)[1:-4])[0]: pd.read_csv(f,names=['id', 'date', 'user', 'text'],low_memory=False) for f in glob.glob('*.csv')}\n",
    "\n",
    "# Assign Labels to twitter dataframes based on search queries\n",
    "for key in dfs.keys():   \n",
    "    if key == 'rage':\n",
    "        dfs[key]['label'] = 'anger'\n",
    "    \n",
    "    if key == 'angry':\n",
    "        dfs[key]['label'] = 'anger'\n",
    "        \n",
    "    elif key == 'fear' :\n",
    "        dfs[key]['label'] = 'fear'\n",
    "        \n",
    "    elif key == 'happy' :\n",
    "        dfs[key]['label'] = 'joy'\n",
    "        \n",
    "    elif key == 'love' :\n",
    "        dfs[key]['label'] = 'love'\n",
    "        \n",
    "    elif key == 'sad' :\n",
    "        dfs[key]['label'] = 'sadness'\n",
    "        \n",
    "    elif key == 'surprise' :\n",
    "        dfs[key]['label'] = 'surprise'\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08dc11be-d43c-4a30-ac3d-25e90ee63c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows of compiled tweets: 4558141 rows\n"
     ]
    }
   ],
   "source": [
    "# Compile and Concatenate labelled twitter dataframes\n",
    "compiled_csvs = pd.concat(dfs,ignore_index=True,axis=0)\n",
    "compiled_csvs = compiled_csvs[['label','text']]\n",
    "compiled_csvs['text'] = compiled_csvs['text'].apply(str)\n",
    "print(f\"Rows of compiled tweets: {len(compiled_csvs)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7207f25e-2cac-4585-9325-10fd873036f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before duplicate removal: 4558141\n",
      "Rows after duplicate removal: 191709\n"
     ]
    }
   ],
   "source": [
    "# Remove Null Values and Drop Duplicate tweets\n",
    "compiled_csvs = compiled_csvs.dropna(subset=['text'])\n",
    "print(f\"Rows before duplicate removal: {compiled_csvs.shape[0]}\")\n",
    "compiled_csvs.drop_duplicates(subset=['text'], keep='first',inplace=True,ignore_index=True)\n",
    "print(f\"Rows after duplicate removal: {compiled_csvs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdcc439-d1be-4271-9199-a42ac0e1666e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>https://t.co/IZSFiF8Rw9 #angry #Dont Make Me A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>â€žFuriosaâ€œ is finishedâ€¦ #wut #rage #projekt #an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>#Freak TFG is #angry #afraid https://t.co/ql68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>Gave up by NIN is such a good song to blast wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>@HDMOVIESOURCE @UniversalPics This seems fair ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0  anger  https://t.co/IZSFiF8Rw9 #angry #Dont Make Me A...\n",
       "1  anger  â€žFuriosaâ€œ is finishedâ€¦ #wut #rage #projekt #an...\n",
       "2  anger  #Freak TFG is #angry #afraid https://t.co/ql68...\n",
       "3  anger  Gave up by NIN is such a good song to blast wh...\n",
       "4  anger  @HDMOVIESOURCE @UniversalPics This seems fair ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_loc = \"C:/Users/russe/Desktop/LDA_Topic_Modeling/data/Datasets/Emotion_Data/Compiled_Tweets/\"\n",
    "filename = \"Labelled_Tweets.csv\"\n",
    "\n",
    "# Export compiled data\n",
    "compiled_csvs.to_csv(save_loc+filename,index=None,header=True)\n",
    "compiled_csvs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892e96d4-849a-4886-8fd9-ad591257e2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sadness     46303\n",
       "love        41803\n",
       "anger       31335\n",
       "fear        30585\n",
       "surprise    27059\n",
       "joy         12949\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_csvs['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38789f40-ee31-44dd-b268-6fa438f5b7c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Up Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90738584-19f7-4c57-9a56-c9c6cdca635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\russe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP Text Processing Libraries\n",
    "import re\n",
    "import nltk\n",
    "from emoji import demojize\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f152b5c4-545f-4bb6-97cb-df6517741218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(texts, quiet=False):\n",
    "    start = time()\n",
    "    \n",
    "    # Lowercasing\n",
    "    texts = texts.str.lower()\n",
    "\n",
    "    # Remove special chars\n",
    "    texts = texts.str.replace(r\"(http|@)\\S+\", \"\",regex=True)\n",
    "    texts = texts.apply(demojize)\n",
    "    texts = texts.str.replace(r\"::\", \": :\",regex=True)\n",
    "    texts = texts.str.replace(r\"â€™\", \"'\",regex=True)\n",
    "    texts = texts.str.replace(r\"[^a-z\\':_]\", \" \",regex=True)\n",
    "\n",
    "    # Remove repetitions\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n",
    "    texts = texts.str.replace(pattern, r\"\\1\",regex=True)\n",
    "\n",
    "    # Transform short negation form\n",
    "    texts = texts.str.replace(r\"(can't|cannot)\", 'can not',regex=True)\n",
    "    texts = texts.str.replace(r\"n't\", ' not',regex=True)\n",
    "\n",
    "    # Remove stop words\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stopwords.remove('not')\n",
    "    stopwords.remove('nor')\n",
    "    stopwords.remove('no')\n",
    "    texts = texts.apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stopwords]))\n",
    "\n",
    "    if not quiet:\n",
    "        print(\"Time to clean up: {:.2f} sec\".format(time() - start))\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8528058-6f35-451d-9b3a-3d10511c9e9f",
   "metadata": {},
   "source": [
    "## Run Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66460707-2d9f-4306-b41c-eb471ca8942e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up: 160.50 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>https://t.co/IZSFiF8Rw9 #angry #Dont Make Me A...</td>\n",
       "      <td>angry dont make angry wouldnt like im angry via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>â€žFuriosaâ€œ is finishedâ€¦ #wut #rage #projekt #an...</td>\n",
       "      <td>furiosa finished wut rage projekt angry angrya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>#Freak TFG is #angry #afraid https://t.co/ql68...</td>\n",
       "      <td>freak tfg angry afraid via assolini feeling ft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>Gave up by NIN is such a good song to blast wh...</td>\n",
       "      <td>gave nin good song blast got fired got fired s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>@HDMOVIESOURCE @UniversalPics This seems fair ...</td>\n",
       "      <td>seems fair respectful would've gone premium pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0  anger  https://t.co/IZSFiF8Rw9 #angry #Dont Make Me A...   \n",
       "1  anger  â€žFuriosaâ€œ is finishedâ€¦ #wut #rage #projekt #an...   \n",
       "2  anger  #Freak TFG is #angry #afraid https://t.co/ql68...   \n",
       "3  anger  Gave up by NIN is such a good song to blast wh...   \n",
       "4  anger  @HDMOVIESOURCE @UniversalPics This seems fair ...   \n",
       "\n",
       "                                        text_cleaned  \n",
       "0    angry dont make angry wouldnt like im angry via  \n",
       "1  furiosa finished wut rage projekt angry angrya...  \n",
       "2  freak tfg angry afraid via assolini feeling ft...  \n",
       "3  gave nin good song blast got fired got fired s...  \n",
       "4  seems fair respectful would've gone premium pr...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_csvs['text_cleaned'] = preprocess(texts=compiled_csvs.text,quiet=False)\n",
    "compiled_csvs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ccf904-1637-41e1-9f44-f6ca93ab7100",
   "metadata": {},
   "source": [
    "## Validate compiled tweets with Sentiment Model Ranging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1091e495-1884-4465-9061-5f5023189fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "# NLP Libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nlp\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "print(f'Tensorflow Version: {tf.version.VERSION}')\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import GlobalAvgPool1D\n",
    "\n",
    "# Auxilliary Libraries\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6c83456-319d-458a-9089-0d4563c7b749",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100, 256)          253440    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,261,697\n",
      "Trainable params: 2,261,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load trained Sentiment Analysis Model with weights and Optimizers\n",
    "model_file = \"C:/Users/russe/Desktop/LDA_Topic_Modeling/data/Models/Sentiment_Analysis/gru_model.h5\"\n",
    "sentiment_model = tf.keras.models.load_model(model_file)\n",
    "\n",
    "# Load trained Sentiment Model Tokenizer\n",
    "tokenizer_path = \"C:/Users/russe/Desktop/LDA_Topic_Modeling/data/Pickles/Sentiment140/tokenizer.pkl\"\n",
    "with open(tokenizer_path,'rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "# Show the model architecture\n",
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee68d56-e546-4f8e-b70e-47e5325dcdc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score_range(mean):\n",
    "    if mean < 0.5:\n",
    "        return (float(\"{0:.4f}\".format(0.0)), float(\"{0:.4f}\".format(mean)))\n",
    "    return (float(\"{0:.4f}\".format(mean)), float(\"{0:.4f}\".format(1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d560c31-bfa5-4b46-b767-1c75e632ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Raw text data & run sentiment analysis scoring\n",
    "cleaned_texts = compiled_csvs.text_cleaned\n",
    "predict_sequences = [text.split() for text in cleaned_texts]\n",
    "list_tokenized_predict = tokenizer.texts_to_sequences(predict_sequences)\n",
    "x_predict = pad_sequences(list_tokenized_predict, maxlen=100)\n",
    "\n",
    "# Assign model predictions to each row of data\n",
    "result = sentiment_model.predict(x_predict)\n",
    "compiled_csvs['Sentiment Score'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66d4d742-7789-49ca-99a8-c19f9b32793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger: Score Range: 0.0 - 0.4441\n",
      "Fear: Score Range: 0.0 - 0.4861\n",
      "Joy: Score Range: 0.9027 - 1.0\n",
      "Love: Score Range: 0.8499 - 1.0\n",
      "Sadness: Score Range: 0.0 - 0.4655\n",
      "Surprise: Score Range: 0.5855 - 1.0\n",
      "\n",
      "Number of validated rows of data: 105872\n"
     ]
    }
   ],
   "source": [
    "# Group by emotion label & store in dictionary format\n",
    "label_group = compiled_csvs.groupby('label')\n",
    "label_group = dict(list(label_group))\n",
    "\n",
    "# assign emotion ranges with dictionary\n",
    "data_list = []\n",
    "emotion_ranges = {}\n",
    "\n",
    "for key,val in label_group.items():\n",
    "    #calculate mean, std & sentiment value range for each label cluster\n",
    "    mean = label_group[key]['Sentiment Score'].mean()\n",
    "    std = label_group[key]['Sentiment Score'].std()\n",
    "    low, high = get_score_range(mean)\n",
    "    # save ranges for each emotion\n",
    "    emotion_ranges[key] =  [low,high]\n",
    "    print(f\"{key.capitalize()}: Score Range: {low} - {high}\")\n",
    "    # Keep only rows with correct label within range\n",
    "    validated_data = label_group[key][np.all([(label_group[key]['Sentiment Score'] >= low), (label_group[key]['Sentiment Score'] <= high)], axis=0)]\n",
    "    data_list.append(validated_data)\n",
    "\n",
    "# Combine all validated, label-grouped data\n",
    "validated_data = pd.concat(data_list,ignore_index=True)\n",
    "print(\"\")\n",
    "print(f\"Number of validated rows of data: {validated_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06383ae2-8e5a-4810-a4ca-249569941e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>https://t.co/IZSFiF8Rw9 #angry #Dont Make Me A...</td>\n",
       "      <td>angry dont make angry wouldnt like im angry via</td>\n",
       "      <td>0.135011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>Gave up by NIN is such a good song to blast wh...</td>\n",
       "      <td>gave nin good song blast got fired got fired s...</td>\n",
       "      <td>0.056593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>@HDMOVIESOURCE @UniversalPics This seems fair ...</td>\n",
       "      <td>seems fair respectful would've gone premium pr...</td>\n",
       "      <td>0.193763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>Pearls of spirituality for #anger .USE S.O.S\\n...</td>\n",
       "      <td>pearls spirituality anger use whenever feel an...</td>\n",
       "      <td>0.333703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>FOR THE LOVE OF EVERYTHING LEARN TO REPLY, NOT...</td>\n",
       "      <td>love everything learn reply not reply respondi...</td>\n",
       "      <td>0.180410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105867</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@nftmomentum @SolatoPotato New NFT coming soon...</td>\n",
       "      <td>new nft coming soon :exploding_head: humanoids...</td>\n",
       "      <td>0.861667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105868</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@Vesperskill @SnoopDogg @CozomoMedici ðŸ¤¯ congra...</td>\n",
       "      <td>:exploding_head: congrats</td>\n",
       "      <td>0.977566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105869</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@Fcxky_Wowly New NFT coming soon! ðŸ¤¯ Humanoids ...</td>\n",
       "      <td>new nft coming soon :exploding_head: humanoids...</td>\n",
       "      <td>0.861667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105870</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@mikiowatanabe6 crazy w these ones!! ðŸ¤¯</td>\n",
       "      <td>crazy w ones :exploding_head:</td>\n",
       "      <td>0.775524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105871</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@BuddyyNFT @Cryptinish New NFT coming soon! ðŸ¤¯ ...</td>\n",
       "      <td>new nft coming soon :exploding_head: humanoids...</td>\n",
       "      <td>0.861667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105872 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                               text  \\\n",
       "0          anger  https://t.co/IZSFiF8Rw9 #angry #Dont Make Me A...   \n",
       "1          anger  Gave up by NIN is such a good song to blast wh...   \n",
       "2          anger  @HDMOVIESOURCE @UniversalPics This seems fair ...   \n",
       "3          anger  Pearls of spirituality for #anger .USE S.O.S\\n...   \n",
       "4          anger  FOR THE LOVE OF EVERYTHING LEARN TO REPLY, NOT...   \n",
       "...          ...                                                ...   \n",
       "105867  surprise  @nftmomentum @SolatoPotato New NFT coming soon...   \n",
       "105868  surprise  @Vesperskill @SnoopDogg @CozomoMedici ðŸ¤¯ congra...   \n",
       "105869  surprise  @Fcxky_Wowly New NFT coming soon! ðŸ¤¯ Humanoids ...   \n",
       "105870  surprise             @mikiowatanabe6 crazy w these ones!! ðŸ¤¯   \n",
       "105871  surprise  @BuddyyNFT @Cryptinish New NFT coming soon! ðŸ¤¯ ...   \n",
       "\n",
       "                                             text_cleaned  Sentiment Score  \n",
       "0         angry dont make angry wouldnt like im angry via         0.135011  \n",
       "1       gave nin good song blast got fired got fired s...         0.056593  \n",
       "2       seems fair respectful would've gone premium pr...         0.193763  \n",
       "3       pearls spirituality anger use whenever feel an...         0.333703  \n",
       "4       love everything learn reply not reply respondi...         0.180410  \n",
       "...                                                   ...              ...  \n",
       "105867  new nft coming soon :exploding_head: humanoids...         0.861667  \n",
       "105868                          :exploding_head: congrats         0.977566  \n",
       "105869  new nft coming soon :exploding_head: humanoids...         0.861667  \n",
       "105870                      crazy w ones :exploding_head:         0.775524  \n",
       "105871  new nft coming soon :exploding_head: humanoids...         0.861667  \n",
       "\n",
       "[105872 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0bc82c6-75b0-4f2a-992b-045f0dfa1677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "love        28864\n",
       "sadness     22495\n",
       "anger       15862\n",
       "fear        14980\n",
       "surprise    14048\n",
       "joy          9623\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validated_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7463024e-9292-41c8-bd8c-196aa290688e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105872, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "111948cb-1913-4502-8e53-faa7a66a8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc = \"C:/Users/russe/Desktop/LDA_Topic_Modeling/data/Datasets/Emotion_Data/Compiled_Tweets/\"\n",
    "filename = \"validated_data.csv\"\n",
    "validated_data.to_csv(save_loc+filename, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1545ab-98a7-4585-81f8-56dcd4d57117",
   "metadata": {},
   "source": [
    "## Check currently Validated Data being run on Task Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a04b99f-d577-4de6-8b03-da654de95d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "love        28864\n",
       "sadness     22495\n",
       "anger       15862\n",
       "fear        14980\n",
       "surprise    14048\n",
       "joy          9623\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data = pd.read_csv(save_loc+filename)\n",
    "read_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c7e99-a3b7-4bdc-a4fc-63e101d0160c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
